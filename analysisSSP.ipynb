{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from boruta import BorutaPy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Read-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4 = pd.DataFrame(data={'id':[],\n",
    "                             'created_at':[],\n",
    "                             'updated_at':[],\n",
    "                             'deleted_at':[],\n",
    "                             'timestamp':[],\n",
    "                             'user_id':[],\n",
    "                             'clicked_left':[],\n",
    "                             'clicked_right':[],\n",
    "                             'on_screen':[],\n",
    "                             'screen_loc':[],\n",
    "                             'x':[],\n",
    "                             'y':[],\n",
    "                             'screen_width':[],\n",
    "                             'screen_height':[]})\n",
    "\n",
    "probes = pd.read_csv('probes.csv',sep='\\t', encoding='utf-8', header=None)\n",
    "probes.columns = ['id','created_at','updated_at','deleted_at','timestamp',\n",
    "                  'user_id','answer','page_nr','delay_time','time_to_answer']\n",
    "\n",
    "# For some reason only 12 columns for 13 categories?\n",
    "# questionnaires = pd.read_csv('questionnaires.csv',sep='\\t', encoding='utf-8', header=None)\n",
    "# questionnaires.columns = ['id','created_at','updated_at','deleted_at','screen_width',\n",
    "#                           'screen_height','age','gender','level_of_education',\n",
    "#                           'distraction','using_mouse','read_war_and_peace','read_grimm']\n",
    "\n",
    "questions = pd.read_csv('questions.csv',sep='\\t', encoding='utf-8', header=None)\n",
    "questions.columns = ['id','created_at','updated_at','deleted_at','user_id',\n",
    "                     'correct','page_nr','book']\n",
    "\n",
    "records = pd.read_csv('records.csv',sep='\\t', encoding='utf-8', header=None)\n",
    "records.columns=c4.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some relevant statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.4% not mindwandering, 28.6% mindwandering\n",
      "# users who started experiment: 29, # users who finished experiment: 24\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([0 if val.answer in [1,2] else 1 for _,val in probes.iterrows()])\n",
    "\n",
    "_,count = np.unique(labels,return_counts=True)\n",
    "percs = np.round(count/np.sum(count)*100,1)\n",
    "print(\"{}% not mindwandering, {}% mindwandering\".format(percs[0], percs[1]))\n",
    "\n",
    "# users who did not finish the experiment\n",
    "usrs_all = np.unique(probes.user_id)\n",
    "blacklist = usrs_all[np.array([len(probes.user_id.loc[probes.user_id==usr]) for usr in usrs_all])<6]\n",
    "print(\"# users who started experiment: {}, # users who finished experiment: {}\".format(len(usrs_all), len(usrs_all)-len(blacklist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def _normalize_coords(self, df):\n",
    "        df['x_norm'] = df.x/df.screen_width\n",
    "        df['y_norm'] = df.y/df.screen_height\n",
    "        loc_norm = []\n",
    "        for usr in np.unique(df.user_id):\n",
    "            df_usr = df.loc[df.user_id==usr]\n",
    "            loc_norm = loc_norm+list(df_usr.screen_loc/df_usr.screen_loc.max())\n",
    "        df['loc_norm'] = loc_norm\n",
    "        return df\n",
    "\n",
    "    def _get_polar(self, df):\n",
    "        df['cur_polar'] = np.arctan2(list(df.y_norm),list(df.x_norm))\n",
    "        df['cur_velocity'] = np.sqrt(list(df.x_norm**2 + df.y_norm**2))\n",
    "        return df\n",
    "\n",
    "    def _get_trajectories(self,df):\n",
    "        traj_loc = []\n",
    "        traj_cur =  []\n",
    "        for usr in np.unique(df.user_id):\n",
    "            df_usr = df.loc[df.user_id==usr]\n",
    "            traj_loc = traj_loc + list(df_usr.loc_norm.rolling(2).apply(lambda x: x[1]-x[0],raw=True))\n",
    "            traj_cur = traj_cur + list(np.arctan2(df_usr.x_norm.rolling(2).apply(lambda x: x[1]-x[0],raw=True),\n",
    "                                                  df_usr.y_norm.rolling(2).apply(lambda x: x[1]-x[0],raw=True)))\n",
    "        df['traj_loc'] = traj_loc\n",
    "        df['traj_cur'] = traj_cur\n",
    "        return df\n",
    "    \n",
    "    def _get_hesitation(self,df):\n",
    "        hesitation = []\n",
    "        for user in np.unique(df.user_id):\n",
    "            df_usr = df.loc[df.user_id==user].sort_values('id')\n",
    "            timepts = pd.to_datetime(df_usr.timestamp)\n",
    "            a = pd.to_datetime([np.nan]+list(df_usr.timestamp))\n",
    "            b = pd.to_datetime(list(df_usr.timestamp)+[np.nan])\n",
    "            c = list((b-a).seconds)\n",
    "            hesitation = hesitation + c[:-1]\n",
    "        df['hesitation'] = hesitation\n",
    "        return df\n",
    "\n",
    "    def _slice_probe_windows(self, df):\n",
    "        # interval length = 30 seconds\n",
    "        intervals = []\n",
    "        for _,probe in probes.iterrows():\n",
    "            FMT = '%Y-%m-%d %H:%M:%S'\n",
    "            ts = pd.Timestamp(probe.timestamp)\n",
    "            usr = probe.user_id\n",
    "            if usr in np.unique(df.user_id):\n",
    "                ts_int = pd.Interval(ts-pd.Timedelta(30,unit='seconds'),ts,closed='both')\n",
    "                intervals.append(df.loc[np.logical_and(df.user_id==usr,\n",
    "                                                       [x in ts_int for x in pd.to_datetime(df.timestamp)]),\n",
    "                                        ['x_norm','y_norm','loc_norm','cur_polar','cur_velocity','hesitation',\n",
    "                                         'traj_loc','traj_cur']])\n",
    "        return intervals\n",
    "    \n",
    "    def _average_windows(self, df):\n",
    "        res_mat = pd.DataFrame(columns=df[0].columns)\n",
    "        for interv in df:\n",
    "            res_mat = res_mat.append(pd.DataFrame(np.array(interv.mean()).reshape(1,len(df[0].columns)),\n",
    "                                                  columns=df[0].columns))\n",
    "        return res_mat\n",
    "    \n",
    "    def _fill_na(self, df):\n",
    "        df = df.fillna(0)\n",
    "        return df\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        res_mat = X.copy()\n",
    "        res_mat = self._normalize_coords(res_mat)\n",
    "        res_mat = self._get_polar(res_mat)\n",
    "        res_mat = self._get_trajectories(res_mat)\n",
    "        res_mat = self._get_hesitation(res_mat)\n",
    "        res_mat = self._slice_probe_windows(res_mat)\n",
    "        res_mat = self._average_windows(res_mat)\n",
    "        res_mat = self._fill_na(res_mat)\n",
    "        return res_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7969265d21e46138d6ddf3877514071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left-out subjects:[2. 3.], F1-score:0.294, Precision:0.208, Recall:0.5\n",
      "Left-out subjects:[4. 5.], F1-score:0.455, Precision:0.417, Recall:0.5\n",
      "Left-out subjects:[6. 7.], F1-score:0.455, Precision:0.417, Recall:0.5\n",
      "Left-out subjects:[ 9. 10.], F1-score:0.35, Precision:0.318, Recall:0.389\n",
      "Left-out subjects:[11. 14.], F1-score:0.429, Precision:0.375, Recall:0.5\n",
      "Left-out subjects:[15. 16.], F1-score:0.455, Precision:0.417, Recall:0.5\n",
      "Left-out subjects:[17. 18.], F1-score:0.368, Precision:0.292, Recall:0.5\n",
      "Left-out subjects:[19. 22.], F1-score:0.294, Precision:0.227, Recall:0.417\n",
      "Left-out subjects:[23. 24.], F1-score:0.391, Precision:0.321, Recall:0.5\n",
      "Left-out subjects:[25. 26.], F1-score:0.556, Precision:0.6, Recall:0.818\n",
      "Left-out subjects:[27. 30.], F1-score:1.0, Precision:1.0, Recall:1.0\n",
      "Left-out subjects:[32. 33.], F1-score:0.4, Precision:0.333, Recall:0.5\n",
      "\n",
      "Average F1:0.454, average Precision: 0.41, average Recall: 0.552\n"
     ]
    }
   ],
   "source": [
    "# Convergence warning and only 1 label found in test warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "prec, rec, f1 = [],[],[]\n",
    "\n",
    "usrs = np.array([x for x in usrs_all if x not in blacklist and not np.isnan(x)])\n",
    "idx = 0\n",
    "kf = KFold(n_splits=12)\n",
    "for train, test in tqdm(kf.split(usrs)):\n",
    "#     print('Fold nr: {}/{}, )\n",
    "    X_train = records.loc[[x in usrs[train] for x in records.user_id]]\n",
    "    X_test = records.loc[[x in usrs[test] for x in records.user_id]]\n",
    "    y_train = labels[[x in usrs[train] for x in probes.user_id]]\n",
    "    y_test = labels[[x in usrs[test] for x in probes.user_id]]\n",
    "    rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "    pipe = Pipeline(steps = [('preprocessing', Preprocessor()),#])\n",
    "                             #('feat_select', BorutaPy(rf, n_estimators='auto', verbose=2, random_state=42)),\n",
    "                             ('clf', LinearSVC(max_iter=100000))]).fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    idx+=1\n",
    "    clrp = classification_report(y_test,y_pred, output_dict=True)\n",
    "    f1.append(round(clrp['macro avg']['f1-score'],3))\n",
    "    prec.append(round(clrp['macro avg']['precision'],3))\n",
    "    rec.append(round(clrp['macro avg']['recall'],3))\n",
    "    print('Left-out subjects:{}, F1-score:{}, Precision:{}, Recall:{}'.format(usrs[test],f1[-1],prec[-1],rec[-1]))\n",
    "print('Average F1:{}, average Precision: {}, average Recall: {}'.format(round(np.mean(f1),3), \n",
    "                                                                        round(np.mean(prec),3), \n",
    "                                                                        round(np.mean(rec),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
